# ä»é›¶å¼€å§‹ï¼šMIMIC-IV è¯ç‰©æ¨èæ•°æ®é›†é¢„å¤„ç†æŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®ä½¿ç”¨ MIMIC-IV æ•°æ®é›†æ„å»ºè¯ç‰©æ¨èçš„æ‰©æ•£æ¨¡å‹ï¼Œæ ¸å¿ƒæ€è·¯ï¼š
- **è¾“å…¥**ï¼šæ‚£è€…æ¡ä»¶å‘é‡ï¼ˆ1024 ç»´ï¼‰
- **è¾“å‡º**ï¼šè¯ç‰©ç»„åˆå‘é‡ï¼ˆ189 ç»´ multi-hotï¼‰
- **æ¨¡å‹**ï¼šåŸºäº Multinomial Diffusion çš„ text_diffusion

---

## ğŸ”§ å‰ç½®å‡†å¤‡

### 1. ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.10+
- CUDAï¼ˆå¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿï¼‰

### 2. åˆ›å»º Conda ç¯å¢ƒ

```bash
conda create -n llamafactory python=3.8
conda activate llamafactory
```

### 3. å®‰è£…ä¾èµ–

```bash
pip install torch torchvision
pip install pandas numpy
pip install pyhealth  # MIMIC-IV æ•°æ®åŠ è½½
pip install tqdm
```

### 4. ç¡®è®¤ MIMIC-IV æ•°æ®é›†è·¯å¾„

ç¡®ä¿ä½ æœ‰æƒè®¿é—® MIMIC-IV æ•°æ®é›†ï¼Œè·¯å¾„ä¸ºï¼š
```
/mnt/share/Zhiwen/mimic-iv-2.2/hosp/
```

è¯¥ç›®å½•åº”åŒ…å«ï¼š
- `patients.csv.gz` - æ‚£è€…åŸºæœ¬ä¿¡æ¯
- `admissions.csv.gz` - å…¥é™¢ä¿¡æ¯
- `diagnoses_icd.csv.gz` - è¯Šæ–­ç¼–ç 
- `procedures_icd.csv.gz` - æ‰‹æœ¯ç¼–ç 
- `prescriptions.csv.gz` - å¤„æ–¹ä¿¡æ¯

---

## ğŸš€ å®Œæ•´æ‰§è¡Œæµç¨‹ï¼ˆæŒ‰é¡ºåºè¿è¡Œï¼‰

### æ­¥éª¤ 1: æ„å»ºè¯è¡¨ï¼ˆçº¦ 3-5 åˆ†é’Ÿï¼‰

**ç›®çš„**ï¼šç»Ÿè®¡å¹¶æ„å»ºè¯ç‰©ã€è¯Šæ–­ã€æ‰‹æœ¯çš„è¯è¡¨

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion/datasets

conda activate llamafactory

python build_vocabularies.py \
    --mimic_root /mnt/share/Zhiwen/mimic-iv-2.2/hosp \
    --output_dir ./mimic_drugs \
    --top_k_diagnosis 400 \
    --top_k_procedure 150
```

**ç”Ÿæˆçš„æ–‡ä»¶**ï¼š
```
datasets/mimic_drugs/
â”œâ”€â”€ drug_vocab.json                    # 189 ä¸ª ATC Level 3 è¯ç‰©
â”œâ”€â”€ diagnosis_vocab_aggregated.json    # 401 ä¸ªè¯Šæ–­ç±»ç›®ï¼ˆè¦†ç›–ç‡ 86.39%ï¼‰
â”œâ”€â”€ procedure_vocab_aggregated.json    # 151 ä¸ªæ‰‹æœ¯ç±»ç›®ï¼ˆè¦†ç›–ç‡ 99.99%ï¼‰
â””â”€â”€ vocab_stats.json                   # ç»Ÿè®¡ä¿¡æ¯
```

**é¢„æœŸè¾“å‡ºç¤ºä¾‹**ï¼š
```
============================================================
æ„å»º MIMIC-IV è¯è¡¨
============================================================
1. åŠ è½½ MIMIC-IV æ•°æ®é›†...
2. åº”ç”¨è¯ç‰©æ¨èä»»åŠ¡...
æ€»æ ·æœ¬æ•°: 147,393
è®­ç»ƒé›†æ ·æœ¬æ•°: 103,175
3. ç»Ÿè®¡è¯Šæ–­ç¼–ç é¢‘ç‡...
å”¯ä¸€è¯Šæ–­ç±»ç›®æ•°: 2,877
è¯Šæ–­è®°å½•æ€»æ•°: 5,049,090
4. ç»Ÿè®¡æ‰‹æœ¯ç¼–ç é¢‘ç‡...
å”¯ä¸€æ‰‹æœ¯ç±»ç›®æ•°: 165
æ‰‹æœ¯è®°å½•æ€»æ•°: 904,996
5. ç»Ÿè®¡è¯ç‰©é¢‘ç‡...
å”¯ä¸€è¯ç‰©æ•° (ATC-L3): 189
è¯ç‰©è®°å½•æ€»æ•°: 2,312,505
6. æ„å»ºè¯è¡¨...
è¯Šæ–­è¯è¡¨: ä¿ç•™ top-400 ç±»ç›®ï¼Œè¦†ç›–ç‡: 86.39%
æ‰‹æœ¯è¯è¡¨: ä¿ç•™ top-150 ç±»ç›®ï¼Œè¦†ç›–ç‡: 99.99%
è¯ç‰©è¯è¡¨: 189 ä¸ª ATC-L3 è¯ç‰©
7. ä¿å­˜è¯è¡¨...
âœ“ è¯Šæ–­è¯è¡¨å·²ä¿å­˜: ./mimic_drugs/diagnosis_vocab_aggregated.json
âœ“ æ‰‹æœ¯è¯è¡¨å·²ä¿å­˜: ./mimic_drugs/procedure_vocab_aggregated.json
âœ“ è¯ç‰©è¯è¡¨å·²ä¿å­˜: ./mimic_drugs/drug_vocab.json
âœ“ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: ./mimic_drugs/vocab_stats.json
```

---

### æ­¥éª¤ 2: æµ‹è¯•è¯è¡¨å’Œ Embeddingï¼ˆå¯é€‰ï¼Œçº¦ 1 åˆ†é’Ÿï¼‰

**ç›®çš„**ï¼šéªŒè¯è¯è¡¨æ„å»ºå’Œæ‚£è€…æ¡ä»¶å‘é‡æ„å»ºæ˜¯å¦æ­£å¸¸

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion

conda activate llamafactory

# è¿è¡Œå®Œæ•´æµ‹è¯•
bash quick_start_embedding_v2.sh
```

æˆ–è€…å•ç‹¬æµ‹è¯•ï¼š

```bash
# æµ‹è¯• ICD ä»£ç èšåˆ
python -c "
from datasets.icd_aggregation import aggregate_diagnosis_code, aggregate_procedure_code
print('è¯Šæ–­ 5723 ->', aggregate_diagnosis_code('5723'))
print('è¯Šæ–­ E1165 ->', aggregate_diagnosis_code('E1165'))
print('æ‰‹æœ¯ 5491 ->', aggregate_procedure_code('5491'))
"

# æµ‹è¯• Elixhauser æå–
python datasets/elixhauser.py

# æµ‹è¯• PatientEmbeddingV2
python test_embedding_v2_complete.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
============================================================
æµ‹è¯• 1: ICD ä»£ç èšåˆ
============================================================
âœ“ è¯Šæ–­ 5723 â†’ 572
âœ“ è¯Šæ–­ E1165 â†’ E11
âœ“ æ‰‹æœ¯ 5491 â†’ 54
...ï¼ˆæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼‰
```

---

### æ­¥éª¤ 3: é¢„å¤„ç†æ•°æ®é›†ï¼ˆçº¦ 20-40 åˆ†é’Ÿï¼‰âš ï¸ **æœ€è€—æ—¶**

**ç›®çš„**ï¼š
1. åŠ è½½ MIMIC-IV åŸå§‹æ•°æ®
2. æ„å»ºæ‚£è€…æ¡ä»¶å‘é‡ï¼ˆ1024 ç»´ï¼‰
3. æ„å»ºè¯ç‰©ç»„åˆå‘é‡ï¼ˆ189 ç»´ï¼‰
4. åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆ70%/15%/15%ï¼‰
5. ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®

#### æ–¹æ³• A: ä½¿ç”¨ Python è„šæœ¬ï¼ˆæ¨èï¼‰

åˆ›å»ºè„šæœ¬ `preprocess_all_splits.py`ï¼š

```python
#!/usr/bin/env python3
"""
é¢„å¤„ç†æ‰€æœ‰æ•°æ®é›† splitï¼ˆtrain, valid, testï¼‰
"""
import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from datasets.dataset_mimic import MIMICDrugDataset

def preprocess_all():
    print("=" * 80)
    print("å¼€å§‹é¢„å¤„ç† MIMIC-IV æ•°æ®é›†")
    print("=" * 80)
    
    splits = ['train', 'valid', 'test']
    
    for split in splits:
        print(f"\n{'='*80}")
        print(f"å¤„ç† {split.upper()} é›†")
        print(f"{'='*80}")
        
        try:
            dataset = MIMICDrugDataset(
                root='./datasets',
                split=split,
                max_drugs=190,
                condition_dim=1024,
                mimic_root='/mnt/share/Zhiwen/mimic-iv-2.2/hosp'
            )
            
            print(f"âœ“ {split} é›†é¢„å¤„ç†å®Œæˆ")
            print(f"  - æ ·æœ¬æ•°: {len(dataset)}")
            print(f"  - è¯ç‰©è¯è¡¨å¤§å°: {len(dataset.drug_vocab)}")
            print(f"  - æ¡ä»¶å‘é‡ç»´åº¦: {dataset.condition_dim}")
            
        except Exception as e:
            print(f"âœ— {split} é›†é¢„å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    print("\n" + "=" * 80)
    print("æ‰€æœ‰æ•°æ®é›†é¢„å¤„ç†å®Œæˆï¼")
    print("=" * 80)
    return True

if __name__ == "__main__":
    success = preprocess_all()
    sys.exit(0 if success else 1)
```

è¿è¡Œï¼š

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion

conda activate llamafactory

python preprocess_all_splits.py
```

#### æ–¹æ³• B: ä½¿ç”¨ Python äº¤äº’å¼ï¼ˆäº†è§£ç»†èŠ‚ï¼‰

```python
import sys
sys.path.insert(0, '/home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion')

from datasets.dataset_mimic import MIMICDrugDataset

# é¢„å¤„ç†è®­ç»ƒé›†ï¼ˆçº¦ 15-25 åˆ†é’Ÿï¼‰
print("å¤„ç†è®­ç»ƒé›†...")
train_dataset = MIMICDrugDataset(
    root='./datasets',
    split='train',
    max_drugs=190,
    condition_dim=1024,
    mimic_root='/mnt/share/Zhiwen/mimic-iv-2.2/hosp'
)
print(f"âœ“ è®­ç»ƒé›†: {len(train_dataset)} ä¸ªæ ·æœ¬")

# é¢„å¤„ç†éªŒè¯é›†ï¼ˆçº¦ 3-5 åˆ†é’Ÿï¼‰
print("å¤„ç†éªŒè¯é›†...")
valid_dataset = MIMICDrugDataset(
    root='./datasets',
    split='valid',
    max_drugs=190,
    condition_dim=1024,
    mimic_root='/mnt/share/Zhiwen/mimic-iv-2.2/hosp'
)
print(f"âœ“ éªŒè¯é›†: {len(valid_dataset)} ä¸ªæ ·æœ¬")

# é¢„å¤„ç†æµ‹è¯•é›†ï¼ˆçº¦ 3-5 åˆ†é’Ÿï¼‰
print("å¤„ç†æµ‹è¯•é›†...")
test_dataset = MIMICDrugDataset(
    root='./datasets',
    split='test',
    max_drugs=190,
    condition_dim=1024,
    mimic_root='/mnt/share/Zhiwen/mimic-iv-2.2/hosp'
)
print(f"âœ“ æµ‹è¯•é›†: {len(test_dataset)} ä¸ªæ ·æœ¬")
```

**ç”Ÿæˆçš„æ–‡ä»¶**ï¼š
```
datasets/mimic_drugs/
â”œâ”€â”€ processed_train.pt      # è®­ç»ƒé›†è¯ç‰©å‘é‡ (103,175 Ã— 190)
â”œâ”€â”€ conditions_train.pt     # è®­ç»ƒé›†æ¡ä»¶å‘é‡ (103,175 Ã— 1024)
â”œâ”€â”€ metadata_train.pt       # è®­ç»ƒé›†å…ƒæ•°æ® (subject_id, hadm_id)
â”œâ”€â”€ processed_valid.pt      # éªŒè¯é›†è¯ç‰©å‘é‡ (~22,109 Ã— 190)
â”œâ”€â”€ conditions_valid.pt     # éªŒè¯é›†æ¡ä»¶å‘é‡ (~22,109 Ã— 1024)
â”œâ”€â”€ metadata_valid.pt       # éªŒè¯é›†å…ƒæ•°æ®
â”œâ”€â”€ processed_test.pt       # æµ‹è¯•é›†è¯ç‰©å‘é‡ (~22,109 Ã— 190)
â”œâ”€â”€ conditions_test.pt      # æµ‹è¯•é›†æ¡ä»¶å‘é‡ (~22,109 Ã— 1024)
â””â”€â”€ metadata_test.pt        # æµ‹è¯•é›†å…ƒæ•°æ®
```

**é¢„æœŸè¾“å‡ºç¤ºä¾‹**ï¼š
```
============================================================
å¤„ç† TRAIN é›†
============================================================
Loading patients and admissions data from /mnt/share/Zhiwen/mimic-iv-2.2/hosp...
âœ“ Loaded 299712 patients and 431231 admissions
Preprocessing train data...
Processing 103175 samples for train split
Processing sample 0/103175
Processing sample 1000/103175
...
Processing sample 103000/103175
Saved 103175 samples to ./datasets/mimic_drugs/processed_train.pt
âœ“ train é›†é¢„å¤„ç†å®Œæˆ
  - æ ·æœ¬æ•°: 103175
  - è¯ç‰©è¯è¡¨å¤§å°: 189
  - æ¡ä»¶å‘é‡ç»´åº¦: 1024
```

---

### æ­¥éª¤ 4: éªŒè¯æ•°æ®é›†ï¼ˆçº¦ 1 åˆ†é’Ÿï¼‰

**ç›®çš„**ï¼šç¡®è®¤æ•°æ®é›†é¢„å¤„ç†æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸åŠ è½½

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion

conda activate llamafactory

python test_dataset_mimic_updated.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
â•”==============================================================================â•—
â•‘                    æµ‹è¯•æ›´æ–°åçš„ MIMICDrugDataset                            â•‘
â•š==============================================================================â•

============================================================
æµ‹è¯• 1: åˆ›å»ºè®­ç»ƒé›†
============================================================
âœ“ è®­ç»ƒé›†åˆ›å»ºæˆåŠŸ
  - æ ·æœ¬æ•°: 103175
  - è¯ç‰©è¯è¡¨å¤§å°: 189
  - æ¡ä»¶å‘é‡ç»´åº¦: 1024

============================================================
æµ‹è¯• 2: è·å–æ•°æ®æ ·æœ¬
============================================================
âœ“ æ ·æœ¬è·å–æˆåŠŸ
  - drug_indices shape: torch.Size([190])
  - drug_indices dtype: torch.int64
  - drug_indices unique values: tensor([0, 1])
  - condition_embedding shape: torch.Size([1024])
  - condition_embedding dtype: torch.float32
  - condition_embedding range: [0.0000, 1.0000]
  - max_drugs: 190
âœ“ æ‰€æœ‰ç»´åº¦éªŒè¯é€šè¿‡

============================================================
æµ‹è¯• 3: æ‰¹é‡åŠ è½½
============================================================
âœ“ æ‰¹é‡åŠ è½½æˆåŠŸ
  - drug_batch shape: torch.Size([4, 190])
  - condition_batch shape: torch.Size([4, 1024])
  - max_drugs_batch: tensor([190, 190, 190, 190])
âœ“ æ‰¹é‡ç»´åº¦éªŒè¯é€šè¿‡

============================================================
æµ‹è¯• 4: Metadata å­˜å‚¨
============================================================
âœ“ Metadata åŠ è½½æˆåŠŸ
  - æ ·æœ¬æ•°: 103175
  - å‰ 3 ä¸ªæ ·æœ¬:
    [0] subject_id=10000032, hadm_id=29079034
    [1] subject_id=10000032, hadm_id=26222711
    [2] subject_id=10000048, hadm_id=22595853

============================================================
æµ‹è¯• 5: è¯è¡¨ä¸€è‡´æ€§
============================================================
âœ“ build_vocabularies.py ç”Ÿæˆçš„è¯è¡¨: 189 ä¸ªè¯ç‰©
âœ“ dataset_mimic.py ä½¿ç”¨çš„è¯è¡¨: 189 ä¸ªè¯ç‰©
âœ“ ä¸¤ä¸ªè¯è¡¨å®Œå…¨ä¸€è‡´

============================================================
æµ‹è¯•å®Œæˆ!
============================================================
```

---

## ğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯

å®Œæˆé¢„å¤„ç†åï¼Œä½ å°†å¾—åˆ°ï¼š

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **æ€»æ ·æœ¬æ•°** | 147,393 |
| **è®­ç»ƒé›†** | 103,175 (70%) |
| **éªŒè¯é›†** | ~22,109 (15%) |
| **æµ‹è¯•é›†** | ~22,109 (15%) |
| **è¯ç‰©è¯è¡¨å¤§å°** | 189 ä¸ª ATC Level 3 è¯ç‰© |
| **è¯Šæ–­ç±»ç›®æ•°** | 401 ä¸ªï¼ˆè¦†ç›–ç‡ 86.39%ï¼‰ |
| **æ‰‹æœ¯ç±»ç›®æ•°** | 151 ä¸ªï¼ˆè¦†ç›–ç‡ 99.99%ï¼‰ |
| **è¯ç‰©å‘é‡ç»´åº¦** | 190ï¼ˆ189 ä¸ªè¯ç‰© + 1 ä¸ªä½™é‡ï¼‰ |
| **æ¡ä»¶å‘é‡ç»´åº¦** | 1024 |
| **ç£ç›˜å ç”¨** | ~500 MB - 1 GB |

---

## ğŸ“ æœ€ç»ˆæ–‡ä»¶ç»“æ„

```
text_diffusion/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ mimic_drugs/                    # æ‰€æœ‰é¢„å¤„ç†æ•°æ®
â”‚   â”‚   â”œâ”€â”€ drug_vocab.json             # è¯ç‰©è¯è¡¨
â”‚   â”‚   â”œâ”€â”€ diagnosis_vocab_aggregated.json
â”‚   â”‚   â”œâ”€â”€ procedure_vocab_aggregated.json
â”‚   â”‚   â”œâ”€â”€ vocab_stats.json
â”‚   â”‚   â”œâ”€â”€ processed_train.pt          # è®­ç»ƒé›†æ•°æ®
â”‚   â”‚   â”œâ”€â”€ conditions_train.pt
â”‚   â”‚   â”œâ”€â”€ metadata_train.pt
â”‚   â”‚   â”œâ”€â”€ processed_valid.pt          # éªŒè¯é›†æ•°æ®
â”‚   â”‚   â”œâ”€â”€ conditions_valid.pt
â”‚   â”‚   â”œâ”€â”€ metadata_valid.pt
â”‚   â”‚   â”œâ”€â”€ processed_test.pt           # æµ‹è¯•é›†æ•°æ®
â”‚   â”‚   â”œâ”€â”€ conditions_test.pt
â”‚   â”‚   â””â”€â”€ metadata_test.pt
â”‚   â”œâ”€â”€ dataset_mimic.py                # æ•°æ®é›†ç±»
â”‚   â”œâ”€â”€ patient_embedding_v2.py         # æ‚£è€…æ¡ä»¶å‘é‡æ„å»º
â”‚   â”œâ”€â”€ icd_aggregation.py              # ICD ä»£ç èšåˆ
â”‚   â”œâ”€â”€ elixhauser.py                   # Elixhauser å¹¶å­˜ç—…æå–
â”‚   â””â”€â”€ build_vocabularies.py           # è¯è¡¨æ„å»ºè„šæœ¬
â”œâ”€â”€ test_dataset_mimic_updated.py       # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ test_embedding_v2_complete.py       # Embedding æµ‹è¯•
â”œâ”€â”€ quick_start_embedding_v2.sh         # å¿«é€Ÿæµ‹è¯•è„šæœ¬
â””â”€â”€ ä»é›¶å¼€å§‹ä½¿ç”¨æŒ‡å—.md                  # æœ¬æ–‡ä»¶
```

---

## ğŸ¯ æ•°æ®æ ¼å¼è¯´æ˜

### è¯ç‰©å‘é‡ï¼ˆDï¼‰

- **å½¢çŠ¶**ï¼š`(190,)`
- **ç±»å‹**ï¼š`LongTensor`
- **å–å€¼**ï¼š`{0, 1}`
  - `0` = æœªå¼€æ­¤è¯
  - `1` = å¼€äº†æ­¤è¯
- **ç¤ºä¾‹**ï¼š`[0, 1, 0, 0, 1, 1, 0, ...]`ï¼ˆ189 ä¸ªè¯ç‰©ä½ç½®ï¼‰

### æ¡ä»¶å‘é‡ï¼ˆcï¼‰

- **å½¢çŠ¶**ï¼š`(1024,)`
- **ç±»å‹**ï¼š`FloatTensor`
- **å–å€¼**ï¼šå½’ä¸€åŒ–åçš„æµ®ç‚¹æ•°ï¼ˆé€šå¸¸åœ¨ 0-1 ä¹‹é—´ï¼‰
- **ç»„æˆ**ï¼š

| ç‰¹å¾å— | ç»´åº¦ | ç¼–ç æ–¹å¼ |
|--------|------|----------|
| è¯Šæ–­ç¼–ç  | 400 | Multi-hotï¼ˆICD 3ä½ç±»ç›®ï¼‰ |
| æ‰‹æœ¯ç¼–ç  | 150 | Multi-hotï¼ˆICD 2ä½å¤§ç±»ï¼‰ |
| Elixhauser å¹¶å­˜ç—… | 31 | Binaryï¼ˆ0/1ï¼‰ |
| å†å²ç”¨è¯ | 190 | Multi-hotï¼ˆATC-L3ï¼‰ |
| æ‚£è€…äººå£å­¦ç‰¹å¾ | 253 | è¿ç»­ + One-hot |
| **æ€»è®¡** | **1024** | - |

---

## ğŸ” ä½¿ç”¨æ•°æ®é›†çš„ä»£ç ç¤ºä¾‹

### å•ä¸ªæ ·æœ¬

```python
from datasets.dataset_mimic import MIMICDrugDataset

# åŠ è½½è®­ç»ƒé›†
train_dataset = MIMICDrugDataset(
    root='./datasets',
    split='train',
    max_drugs=190,
    condition_dim=1024
)

# è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬
drug_indices, condition_embedding, max_drugs = train_dataset[0]

print(f"è¯ç‰©å‘é‡: {drug_indices.shape}")        # (190,)
print(f"å¼€äº†å‡ ä¸ªè¯: {drug_indices.sum()}")      # ä¾‹å¦‚: 12
print(f"æ¡ä»¶å‘é‡: {condition_embedding.shape}") # (1024,)
```

### æ‰¹é‡åŠ è½½

```python
from torch.utils.data import DataLoader

# åˆ›å»º DataLoader
train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4
)

# è¿­ä»£æ‰¹æ¬¡
for drug_batch, condition_batch, max_drugs_batch in train_loader:
    # drug_batch: (32, 190)
    # condition_batch: (32, 1024)
    
    # è¿™é‡Œå¯ä»¥å–‚ç»™æ‰©æ•£æ¨¡å‹è®­ç»ƒ
    # loss = model(drug_batch, context=condition_batch)
    # loss.backward()
    # optimizer.step()
    
    break  # åªçœ‹ç¬¬ä¸€ä¸ª batch
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: æŠ¥é”™ "No such file or directory: diagnosis_vocab_aggregated.json"

**åŸå› **ï¼šæ²¡æœ‰å…ˆè¿è¡Œæ­¥éª¤ 1 æ„å»ºè¯è¡¨ã€‚

**è§£å†³**ï¼šå…ˆè¿è¡Œ `build_vocabularies.py`ã€‚

---

### Q2: é¢„å¤„ç†å¾ˆæ…¢ï¼Œå¯ä»¥åŠ é€Ÿå—ï¼Ÿ

**åŸå› **ï¼šéœ€è¦å¤„ç† 10 ä¸‡+ æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬éœ€è¦æ„å»º 1024 ç»´å‘é‡ã€‚

**è§£å†³**ï¼š
- ä½¿ç”¨ SSD ç¡¬ç›˜ï¼ˆè€Œéæœºæ¢°ç¡¬ç›˜ï¼‰
- ç¡®ä¿æœ‰è¶³å¤Ÿå†…å­˜ï¼ˆå»ºè®® 16GB+ï¼‰
- é¦–æ¬¡é¢„å¤„ç†åä¼šä¿å­˜åˆ°ç£ç›˜ï¼Œä¸‹æ¬¡ç›´æ¥åŠ è½½å¾ˆå¿«

---

### Q3: æŠ¥é”™ "Missing subject_id or hadm_id for sample"

**åŸå› **ï¼šæå°‘æ•°æ ·æœ¬å¯èƒ½ç¼ºå°‘ ID ä¿¡æ¯ã€‚

**è§£å†³**ï¼šä»£ç ä¼šè‡ªåŠ¨è·³è¿‡è¿™äº›æ ·æœ¬ï¼Œå±äºæ­£å¸¸ç°è±¡ã€‚

---

### Q4: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è§£å†³**ï¼š
- å‡å°‘ DataLoader çš„ `num_workers`
- å‡å°‘ `batch_size`
- å¢åŠ ç³»ç»Ÿ swap ç©ºé—´

---

### Q5: æƒ³é‡æ–°é¢„å¤„ç†æ€ä¹ˆåŠï¼Ÿ

**è§£å†³**ï¼šåˆ é™¤æ—§æ–‡ä»¶åé‡æ–°è¿è¡Œæ­¥éª¤ 3

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion

rm -f datasets/mimic_drugs/processed_*.pt
rm -f datasets/mimic_drugs/conditions_*.pt
rm -f datasets/mimic_drugs/metadata_*.pt

# ç„¶åé‡æ–°è¿è¡Œé¢„å¤„ç†
python preprocess_all_splits.py
```

---

## âœ… å®Œæˆæ£€æŸ¥æ¸…å•

é¢„å¤„ç†å®Œæˆåï¼Œç¡®è®¤ä»¥ä¸‹æ–‡ä»¶éƒ½å­˜åœ¨ï¼š

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion/datasets/mimic_drugs

ls -lh
```

åº”è¯¥çœ‹åˆ°ï¼š

- [x] `drug_vocab.json` (~10 KB)
- [x] `diagnosis_vocab_aggregated.json` (~20 KB)
- [x] `procedure_vocab_aggregated.json` (~5 KB)
- [x] `vocab_stats.json` (~2 KB)
- [x] `processed_train.pt` (~80 MB)
- [x] `conditions_train.pt` (~400 MB)
- [x] `metadata_train.pt` (~10 MB)
- [x] `processed_valid.pt` (~20 MB)
- [x] `conditions_valid.pt` (~90 MB)
- [x] `metadata_valid.pt` (~2 MB)
- [x] `processed_test.pt` (~20 MB)
- [x] `conditions_test.pt` (~90 MB)
- [x] `metadata_test.pt` (~2 MB)

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š

1. **æŸ¥çœ‹æ—¥å¿—è¾“å‡º**ï¼šæ¯ä¸ªæ­¥éª¤éƒ½ä¼šæ‰“å°è¯¦ç»†ä¿¡æ¯
2. **è¿è¡Œæµ‹è¯•è„šæœ¬**ï¼š`test_dataset_mimic_updated.py`
3. **æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§**ï¼šç¡®è®¤æ‰€æœ‰æ–‡ä»¶éƒ½ç”Ÿæˆäº†

---

## ğŸ‰ å®Œæˆï¼

å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸè¿è¡Œï¼Œä½ ç°åœ¨å·²ç»å®Œæˆäº†æ•°æ®é¢„å¤„ç†ï¼

ä¸‹ä¸€æ­¥å¯ä»¥ï¼š
- è®­ç»ƒæ‰©æ•£æ¨¡å‹
- æ„å»º MCTS å¥–åŠ±å‡½æ•°
- è¿›è¡Œè¯ç‰©æ¨èé¢„æµ‹

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-21  
**ä½œè€…**: Your Team

