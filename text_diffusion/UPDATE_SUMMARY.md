# dataset_mimic.py æ›´æ–°æ€»ç»“

## ğŸ“ æ›´æ–°æ¦‚è¿°

æˆåŠŸå°† `dataset_mimic.py` æ›´æ–°ä¸ºä½¿ç”¨ `PatientEmbeddingV2`ï¼Œç°åœ¨æ”¯æŒç”Ÿæˆ **1024 ç»´**çš„æ‚£è€…æ¡ä»¶å‘é‡ã€‚

---

## âœ… å…·ä½“æ›´æ”¹

### 1. å¯¼å…¥æ¨¡å—æ›´æ–°

```python
# æ–°å¢
import pandas as pd
```

### 2. `__init__` æ–¹æ³•æ›´æ–°

**æ–°å¢å‚æ•°**ï¼š
```python
mimic_root='/mnt/share/Zhiwen/mimic-iv-2.2/hosp'  # MIMIC-IV æ•°æ®è·¯å¾„
```

**æ–°å¢ä»£ç **ï¼š
```python
# åŠ è½½ patients å’Œ admissions æ•°æ®
patients_file = os.path.join(mimic_root, 'patients.csv.gz')
admissions_file = os.path.join(mimic_root, 'admissions.csv.gz')

self.patients_df = pd.read_csv(patients_file, compression='gzip')
self.admissions_df = pd.read_csv(admissions_file, compression='gzip')

# ä¼ é€’ç»™ PatientEmbeddingV2
self.patient_embedding = PatientEmbeddingV2(
    drug_vocab=self.drug_vocab,
    vocab_dir=self.root,
    patients_df=self.patients_df,      # æ–°å¢
    admissions_df=self.admissions_df,  # æ–°å¢
    condition_dim=condition_dim
)

# åŠ è½½ metadata
self.sample_metadata = torch.load(self.metadata_file(split))
```

### 3. `_preprocess_data` æ–¹æ³•æ›´æ–°

**æ–°å¢åŠŸèƒ½**ï¼š
- ä¿å­˜ `(subject_id, hadm_id)` å…ƒæ•°æ®
- è·³è¿‡ç¼ºå°‘ ID çš„æ ·æœ¬
- ä¼ é€’ `subject_id` å’Œ `hadm_id` åˆ° embedding æ–¹æ³•

**å…³é”®ä»£ç **ï¼š
```python
sample_metadata = []  # æ–°å¢

for i, sample in enumerate(samples):
    # æå– subject_id å’Œ hadm_id
    subject_id = sample.get('subject_id', sample.get('patient_id', None))
    hadm_id = sample.get('visit_id', None)
    
    if subject_id is None or hadm_id is None:
        print(f"Warning: Missing subject_id or hadm_id for sample {i}, skipping")
        continue
    
    # ä¼ é€’ç»™ embedding æ–¹æ³•
    condition_embedding = self._create_condition_embedding(sample, subject_id, hadm_id)
    
    # ä¿å­˜ metadata
    sample_metadata.append((subject_id, hadm_id))

# ä¿å­˜ metadata
torch.save(sample_metadata, self.metadata_file(split))
```

### 4. `_create_condition_embedding` æ–¹æ³•æ›´æ–°

**æ—§ç­¾å**ï¼š
```python
def _create_condition_embedding(self, sample):
```

**æ–°ç­¾å**ï¼š
```python
def _create_condition_embedding(self, sample, subject_id, hadm_id):
```

**è°ƒç”¨æ–¹å¼**ï¼š
```python
return self.patient_embedding.create_condition_embedding(sample, subject_id, hadm_id)
```

### 5. æ–°å¢ `metadata_file` æ–¹æ³•

```python
def metadata_file(self, split):
    return os.path.join(self.root, f'metadata_{split}.pt')
```

### 6. å…¶ä»–å°æ”¹è¿›

- ç»Ÿä¸€ä½¿ç”¨ `self.mimic_root` æ›¿ä»£ç¡¬ç¼–ç è·¯å¾„
- æ›´æ–°æ³¨é‡Šè¯´æ˜è¯ç‰©æ•°é‡ä¸º 189 ä¸ª

---

## ğŸ“Š æ•°æ®æ ¼å¼å˜åŒ–

### æ—§ç‰ˆæœ¬ï¼ˆ512 ç»´ï¼‰

| ç‰¹å¾ | ç»´åº¦ |
|------|------|
| è¯Šæ–­ embedding | 256 |
| æ‰‹æœ¯ embedding | 128 |
| å†å²ç”¨è¯ | 128 |
| **æ€»è®¡** | **512** |

### æ–°ç‰ˆæœ¬ï¼ˆ1024 ç»´ï¼‰âœ¨

| ç‰¹å¾å— | ç»´åº¦ | ç¼–ç æ–¹å¼ |
|--------|------|----------|
| è¯Šæ–­ç¼–ç  | 400 | Multi-hotï¼ˆICD 3ä½ç±»ç›®ï¼Œtop-400ï¼‰ |
| æ‰‹æœ¯ç¼–ç  | 150 | Multi-hotï¼ˆICD 2ä½å¤§ç±»ï¼Œtop-150ï¼‰ |
| Elixhauser å¹¶å­˜ç—… | 31 | Binaryï¼ˆ0/1ï¼‰ |
| å†å²ç”¨è¯ | 190 | Multi-hotï¼ˆATC-L3ï¼‰ |
| æ‚£è€…äººå£å­¦ç‰¹å¾ | 253 | è¿ç»­ + One-hot |
| **æ€»è®¡** | **1024** | - |

---

## ğŸ—‚ï¸ ç”Ÿæˆçš„æ–°æ–‡ä»¶

```
datasets/mimic_drugs/
â”œâ”€â”€ metadata_train.pt    # æ–°å¢ï¼šè®­ç»ƒé›†å…ƒæ•°æ®
â”œâ”€â”€ metadata_valid.pt    # æ–°å¢ï¼šéªŒè¯é›†å…ƒæ•°æ®
â””â”€â”€ metadata_test.pt     # æ–°å¢ï¼šæµ‹è¯•é›†å…ƒæ•°æ®
```

æ¯ä¸ª metadata æ–‡ä»¶åŒ…å«ï¼š
```python
[
    (subject_id_1, hadm_id_1),
    (subject_id_2, hadm_id_2),
    ...
]
```

---

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### åˆ›å»ºæ•°æ®é›†

```python
from datasets.dataset_mimic import MIMICDrugDataset

# åˆ›å»ºè®­ç»ƒé›†ï¼ˆä¼šè‡ªåŠ¨é¢„å¤„ç†ï¼‰
train_dataset = MIMICDrugDataset(
    root='./datasets',
    split='train',
    max_drugs=190,
    condition_dim=1024,  # ä½¿ç”¨ 1024 ç»´æ¡ä»¶å‘é‡
    mimic_root='/mnt/share/Zhiwen/mimic-iv-2.2/hosp'
)

# è·å–æ ·æœ¬
drug_indices, condition_embedding, max_drugs = train_dataset[0]
# drug_indices: (190,) LongTensor, å€¼ä¸º {0, 1}
# condition_embedding: (1024,) FloatTensor, å½’ä¸€åŒ–åçš„æµ®ç‚¹æ•°
# max_drugs: 190
```

### æ‰¹é‡åŠ è½½

```python
from torch.utils.data import DataLoader

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

for drug_batch, condition_batch, max_drugs_batch in train_loader:
    # drug_batch: (32, 190)
    # condition_batch: (32, 1024)
    # max_drugs_batch: (32,)
    pass
```

---

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯æ›´æ–°ï¼š

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion

# æ–¹æ³• 1: ä½¿ç”¨å¿«é€Ÿæµ‹è¯•è„šæœ¬
./quick_test_dataset.sh

# æ–¹æ³• 2: ç›´æ¥è¿è¡Œæµ‹è¯•
conda activate llamafactory
python test_dataset_mimic_updated.py
```

æµ‹è¯•å†…å®¹ï¼š
1. âœ… æ•°æ®é›†åˆ›å»º
2. âœ… æ ·æœ¬è·å–
3. âœ… æ‰¹é‡åŠ è½½
4. âœ… Metadata å­˜å‚¨
5. âœ… è¯è¡¨ä¸€è‡´æ€§

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. åˆ é™¤æ—§çš„é¢„å¤„ç†æ–‡ä»¶

å¦‚æœä¹‹å‰è¿è¡Œè¿‡æ—§ç‰ˆæœ¬ï¼Œéœ€è¦åˆ é™¤æ—§çš„é¢„å¤„ç†æ–‡ä»¶ï¼š

```bash
cd /home/zhuwei/zhangjian/MCTScode/mct_diffusion2/multinomial_diffusion-main/text_diffusion

rm -f datasets/mimic_drugs/processed_*.pt
rm -f datasets/mimic_drugs/conditions_*.pt
rm -f datasets/mimic_drugs/metadata_*.pt
```

### 2. ç¡®ä¿è¯è¡¨å·²æ„å»º

è¿è¡Œæ•°æ®é›†å‰å¿…é¡»å…ˆæ„å»ºè¯è¡¨ï¼š

```bash
cd datasets

python build_vocabularies.py \
    --mimic_root /mnt/share/Zhiwen/mimic-iv-2.2/hosp \
    --output_dir ./mimic_drugs \
    --top_k_diagnosis 400 \
    --top_k_procedure 150
```

### 3. é¢„å¤„ç†æ—¶é—´

é¦–æ¬¡è¿è¡Œä¼šè§¦å‘é¢„å¤„ç†ï¼Œå¤§çº¦éœ€è¦ï¼š
- è®­ç»ƒé›†ï¼ˆ103,175 æ ·æœ¬ï¼‰ï¼šçº¦ 15-30 åˆ†é’Ÿ
- éªŒè¯é›†ï¼ˆ~22,109 æ ·æœ¬ï¼‰ï¼šçº¦ 3-5 åˆ†é’Ÿ
- æµ‹è¯•é›†ï¼ˆ~22,109 æ ·æœ¬ï¼‰ï¼šçº¦ 3-5 åˆ†é’Ÿ

---

## ğŸ› å·²çŸ¥é—®é¢˜

### é—®é¢˜ 1: PyHealth çš„ visit_id æ˜ å°„

**æè¿°**ï¼šPyHealth ä½¿ç”¨ `visit_id` ä½œä¸º `hadm_id` çš„é”®åã€‚

**è§£å†³**ï¼šä»£ç ä¸­å·²å¤„ç†ï¼š
```python
hadm_id = sample.get('visit_id', None)
```

### é—®é¢˜ 2: éƒ¨åˆ†æ ·æœ¬ç¼ºå°‘ ID

**æè¿°**ï¼šæå°‘æ•°æ ·æœ¬å¯èƒ½ç¼ºå°‘ `subject_id` æˆ– `hadm_id`ã€‚

**è§£å†³**ï¼šä»£ç ä¸­å·²è·³è¿‡è¿™äº›æ ·æœ¬ï¼š
```python
if subject_id is None or hadm_id is None:
    print(f"Warning: Missing subject_id or hadm_id for sample {i}, skipping")
    continue
```

---

## ğŸ“ˆ æ€§èƒ½å½±å“

### ç»´åº¦å¢åŠ 

| æŒ‡æ ‡ | æ—§ç‰ˆæœ¬ (512) | æ–°ç‰ˆæœ¬ (1024) | å˜åŒ– |
|------|--------------|---------------|------|
| æ¡ä»¶å‘é‡ç»´åº¦ | 512 | 1024 | +100% |
| å†…å­˜å ç”¨ï¼ˆä¼°è®¡ï¼‰ | ~200 MB | ~400 MB | +100% |
| é¢„å¤„ç†æ—¶é—´ | ~10 min | ~15 min | +50% |

### æ¨¡å‹å½±å“

- éœ€è¦æ›´æ–° `model.py` ä¸­çš„ `context_proj` å±‚ï¼š
  ```python
  self.context_proj = nn.Linear(1024, transformer_dim)  # ä» 512 æ”¹ä¸º 1024
  ```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [DATASET_MIMIC_USAGE.md](./DATASET_MIMIC_USAGE.md) - è¯¦ç»†ä½¿ç”¨è¯´æ˜
- [README_EMBEDDING_V2.md](./README_EMBEDDING_V2.md) - PatientEmbeddingV2 æ–‡æ¡£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
- [IMPLEMENTATION_SUMMARY.md](./IMPLEMENTATION_SUMMARY.md) - å®ç°æ€»ç»“

---

## âœ¨ åç»­æ­¥éª¤

1. âœ… **dataset_mimic.py å·²æ›´æ–°** - é›†æˆ PatientEmbeddingV2
2. â³ **æ›´æ–° model.py** - ä¿®æ”¹æ”¯æŒ 1024 ç»´æ¡ä»¶è¾“å…¥
3. â³ **é¢„å¤„ç†æ•°æ®** - ç”Ÿæˆæ‰€æœ‰ split çš„æ•°æ®
4. â³ **è®­ç»ƒæ¨¡å‹** - ä½¿ç”¨æ–°æ•°æ®é›†è®­ç»ƒ
5. â³ **æ„å»ºå¥–åŠ±å‡½æ•°** - åŸºäºè®­ç»ƒå¥½çš„æ¨¡å‹

---

**æ›´æ–°æ—¥æœŸ**: 2025-10-20  
**ç‰ˆæœ¬**: v2.0  
**ä½œè€…**: AI Assistant


